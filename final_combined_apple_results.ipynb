{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fbf38a9-0065-4dc5-bed0-b40b37248aa5",
   "metadata": {},
   "source": [
    "# Merged results and remove duplicates\n",
    "## Apple Store (Round 1 + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a3b3d8a-2ab4-4e71-9c3d-d314473d144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1d2983-096c-4c94-b13b-ba526377a70b",
   "metadata": {},
   "source": [
    "### Define some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aab22ab-9e62-4759-972c-95a74274a77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "file_unique = \"final_results_apple_bystander_unique.csv\"\n",
    "clean_dir1 = \"cleaned/apple/03_08_2022/\"\n",
    "clean_dir2 = \"cleaned/apple/16_05_2023/\"\n",
    "out_dir = \"final_results/\"\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdbd998-fe5a-43db-ba57-2839690ab337",
   "metadata": {},
   "source": [
    "### Read each file and process it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fba0d7c9-ff3d-417d-abc1-0e0e977ba29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1) Reading File 1 ... 87 rows\n",
      "2) Reading File 2 ... 87 rows\n",
      "3) Merging dataframes ... 174 rows\n",
      "------------------------\n",
      "4) Created CSV with duplicates: 174 rows.\n",
      "5) Created final CSV without duplicates: 87 rows.\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(\"1) Reading File 1 ...\", end=\" \")\n",
    "df = pd.read_csv(clean_dir1 + file_unique, sep=',', header = 0, dtype='unicode')\n",
    "num_rows = len(df.index)\n",
    "print(str(num_rows) + \" rows\") \n",
    "\n",
    "print(\"2) Reading File 2 ...\", end=\" \")\n",
    "df2 = pd.read_csv(clean_dir2 + file_unique, sep=',', header = 0, dtype='unicode')\n",
    "num_rows2 = len(df2.index)\n",
    "print(str(num_rows2) + \" rows\")\n",
    "\n",
    "print(\"3) Merging dataframes ...\", end=\" \")\n",
    "df['round'] = 1\n",
    "df2['round'] = 2\n",
    "df = pd.concat([df,df2])\n",
    "num_rows3 = len(df.index)\n",
    "print(str(num_rows3) + \" rows\")\n",
    "\n",
    "#sort, delete and redo dupe count for this merged dataset\n",
    "df.sort_values(by=['appid', 'pref'], inplace=True)\n",
    "df['dupes_merged']=df.groupby('appid').appid.transform('count')-1\n",
    "\n",
    "#save dataframe with dupes to csv\n",
    "print(\"------------------------\")\n",
    "df.to_csv(out_dir + \"merged_results_apple_bystander_w_dupes.csv\", index = False)\n",
    "print (\"4) Created CSV with duplicates: \" + str(num_rows3) + \" rows.\")\n",
    "\n",
    "#remove duplicates\n",
    "df.drop(['dupe_count'], axis=1, inplace=True)\n",
    "df = df.drop_duplicates(subset=['appid'], keep='last')\n",
    "num_rows_uni = len(df.index)\n",
    "\n",
    "#save unique dataframe to csv\n",
    "df.to_csv(out_dir + \"merged_results_apple_bystander_unique.csv\", index = False)\n",
    "print (\"5) Created final CSV without duplicates: \" + str(num_rows_uni) + \" rows.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
